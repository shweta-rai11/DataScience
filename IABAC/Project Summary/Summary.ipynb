{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d7db398",
   "metadata": {},
   "source": [
    "# PROJECT- INX Future Inc Employee Performance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e502acad",
   "metadata": {},
   "source": [
    "- Candidate Name : SWETA RAI\n",
    "- Candidate E-Mail : swetaraibms1998@gmail.com\n",
    "- Project Code : 10281\n",
    "- Assessment ID :E10901-PR2-V18\n",
    "- REP Name : DataMites™ Solutions Pvt Ltd\n",
    "- Module : Certified Data Scientist - Project\n",
    "- Exam Format : Open Project- IABAC™ Project Submission\n",
    "- Project Assessment : IABAC™\n",
    "- Registered Trainer : ASHOK KUMAR A\n",
    "- Project Starting Date : 7-April-2023\n",
    "- Submission Deadline Date: 17-April-2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d90342",
   "metadata": {},
   "source": [
    "# SUMMARY OF THE PROJECT-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaa217e",
   "metadata": {},
   "source": [
    "## BUSINESS CASE-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91872be7",
   "metadata": {},
   "source": [
    "- INX Future Inc , (referred as INX ) , is one of the leading data analytics and automation solutions provider\n",
    "  with over 15 years of global business presence. INX is consistently rated as top 20 best employers past 5\n",
    "  years. \n",
    "- INX human resource policies are considered as employee friendly and widely perceived as best\n",
    "  practices in the industry.\n",
    "  Recent years, the employee performance indexes are not healthy    and this is becoming a growing\n",
    "  concerns among the top management. There has been increased escalations on service delivery and\n",
    "  client satisfaction levels came down by 8 percentage points.\n",
    "  CEO, Mr. Brain, knows the issues but concerned to take any     actions in penalizing non-performing\n",
    "  employees as this would affect the employee morale of all the employees in general and may further\n",
    "  reduce the performance. Also, the market perception best employer and thereby attracting best talents\n",
    "  to join the company.\n",
    "- Mr. Brain decided to initiate a data science project , which analyses the current employee data and find\n",
    "  the core underlying causes of this performance issues. Mr. Brain, being a data scientist himself, expects\n",
    "  the findings of this project will help him to take right course of actions. He also expects a clear indicators\n",
    "  of non performing employees, so that any penalization of non-performing employee, if required, may\n",
    "  not significantly affect other employee morals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3ef784",
   "metadata": {},
   "source": [
    "# PROBLEM STATEMENT-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88368b8d",
   "metadata": {},
   "source": [
    "- As per the business case, in the recent years the employee performance indexes are not healthy  and the client's satisfaction levels came down by 8 percentage points so in order to increase the business, the company is actively looking to initiate a data science project to analyse the performance rating of the employees to get a clear indication about the factors which are affecting the performance rating of the employees and also to analyse which group of employees are performing well and which are not.\n",
    "- It is a multiclass classification problem, as the problem statement is to find out the performance rating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cd8c46",
   "metadata": {},
   "source": [
    "# Requirement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d9a368",
   "metadata": {},
   "source": [
    "- This IABAC project include a dummy data shared by IABAC for project analysis, in which the data source is IABAC™.\n",
    "- INX Future Inc , (referred as INX ), is one of the leading data analytics and automation solutions provider with over 15 years of global business presence. INX is consistently rated as top 20 best employers past 5 years.The data is based on INX Future Inc.\n",
    "- INX is consistently rated as top 20 best employers past 5 years.\n",
    "- The entire project was done in multiple platforms which includes Jupiter notebook and VSCode with python platform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e02bb9",
   "metadata": {},
   "source": [
    "# Analysis of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de394945",
   "metadata": {},
   "source": [
    "- Initially domain analysis was done for each and every features for better understanding of the features.\n",
    "- By undergoing some basic checks, it was found that the data consist of both numerical and categorical features.\n",
    "\n",
    "**INTERPRETING THE DATA**\n",
    "\n",
    "**Numerical features includes**\n",
    "- Age\n",
    "- DistanceFromHome\n",
    "- EmpEducationLevel\n",
    "- EmpEnvironmentSatisfaction\n",
    "- EmpHourlyRate\n",
    "- EmpJobInvolvement\n",
    "- EmpJobLevel\n",
    "- EmpJobSatisfaction\n",
    "- NumCompaniesWorked,\n",
    "- EmpLastSalaryHikePercent\n",
    "- EmpRelationshipSatisfaction\n",
    "- TotalWorkExperienceInYears,\n",
    "- TrainingTimesLastYear,\n",
    "- EmpWorkLifeBalance\n",
    "- ExperienceYearsAtThisCompany\n",
    "- ExperienceYearsInCurrentRole\n",
    "- YearsSinceLastPromotion\n",
    "- YearsWithCurrManager\n",
    "\n",
    "**Categorical features includes**\n",
    "- Gender\n",
    "- EducationBackground\n",
    "- MaritalStatus\n",
    "- EmpDepartment\n",
    "- EmpJobRole\n",
    "- BusinessTravelFrequency\n",
    "- OverTime\n",
    "- Attrition\n",
    "\n",
    "**Exploratory data analysis was done for better understanding and to draw necessary insights from the data.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de528ca8",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27697a26",
   "metadata": {},
   "source": [
    "**External**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d81257",
   "metadata": {},
   "source": [
    "- The data was extracted from the link provided by IABAC.\n",
    "- This data is from INX future Inc, where they wanted to explore Machine learning in order to benifit their organization.\n",
    "- The provider had demanded certain reports that need to be speecified and executed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8aba0d",
   "metadata": {},
   "source": [
    "**Processed**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ed8542",
   "metadata": {},
   "source": [
    "- Various Visualization Techniques as well as Pre-processing techniques were used to transform the raw dataset into a proper model building dataset.\n",
    "- The dataset underwent many analysis process in order to extract "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc569c5",
   "metadata": {},
   "source": [
    "**Raw**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fc9565",
   "metadata": {},
   "source": [
    "- This dataset was in raw excel form.\n",
    "- This data set had a collection of Employee details such as (Age,Gender,job role, etc)\n",
    "- This Raw data set has 1200 rows and 28 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d594e2",
   "metadata": {},
   "source": [
    "# Jupyter Notebook\n",
    "- The Jupyter Notebook is a web-based interactive computing platform. The notebook combines live code, equations, narrative text, visualizations.\n",
    "- The jupyter notebook is used in this project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fa0009",
   "metadata": {},
   "source": [
    "# Tools and Libraries used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d7af0a",
   "metadata": {},
   "source": [
    "- **Numpy** - NumPy is a Python library used for working with arrays. It also has functions for working in domain of linear algebra, fourier transform, and matrices.NumPy is a general-purpose array-processing package. It provides a high-performance multidimensional array object, and tools for working \n",
    "\n",
    "- **Pandas** - Pandas is a Python library used for working with data sets. It has functions for analyzing, cleaning, exploring, and manipulating data. The name \"Pandas\" has a reference to both \"Panel Data\", and \"Python Data Analysis\" and was created by Wes McKinney in 2008.Pandas is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool, built on top of the Python programming language.\n",
    "\n",
    "- **Matplotlib** is a comprehensive library for creating static, animated, and interactive visualizations in Python.Matplotlib is an amazing visualization library in Python for 2D plots of arrays. Matplotlib is a multi-platform data visualization library.\n",
    "\n",
    "- **Seaborn** - Seaborn is a Python data visualization library and open source libray based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical.\n",
    "\n",
    "- **Scikit-learn** - Scikit-learn is an open source data analysis library, and the gold standard for Machine Learning (ML) in the Python ecosystem.scikit-learn is a Python module for machine learning built on top of SciPy and is distributed under the 3-Clause BSD license.\n",
    "\n",
    "- **Scipy** -SciPy stands for Scientific Python. It provides more utility functions for optimization, stats and signal processing. Like NumPy, SciPy is open source."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75da95f",
   "metadata": {},
   "source": [
    "# Insights expected from this project\n",
    "\n",
    "**Department wise performances**\n",
    "- Higher performance indicates 1 and lower performance indicates 0\n",
    "- Report shows that the development department has highest           performance rating of 3 i.e higher performance rating\n",
    "- Among all the departments data science has the lowest perfromance   rating of 2 and 4. This indicates that the employees in data       science department have average performance rating.\n",
    "- In almost all the departments, the performance rating 3 is highly   seen and the performancee rating 4 is rarely seen.\n",
    "- However the performance rating 4 is seen in Sales, Development     and Research and development department and not comparatively       less seen in Human resource, Data science and Finance.\n",
    "- So, in order to bring up good performance of the EmpDepartment, \n",
    "  Sales, Development and Research and development department should   be taken care of.\n",
    "  \n",
    "**Top 3 Important Factors effecting employee performance**\n",
    "- EmpSatisfaction\n",
    "- ExperienceYearsAtThisCompany\n",
    "- YearsSinceLastPromotion\n",
    "\n",
    "**A trained model which can predict the employee performance based on factors as inputs. This\n",
    "will be used to hire employees**\n",
    "- To predict the performance of the employees the following models can be considered.\n",
    "\n",
    "- **Support Vector Machine(calssifier)**- 98.99%(training accuracy),92.6%(testing accuracy)\n",
    "- **Decision Tree(tuned)** 98.04%(training accuracy), 96.33%(testing accuracy)\n",
    "- **Random Forest(tuned)** - 99.46%(training accuracy), 96.33%(testing accuracy)\n",
    "- **Gradient boosting** - 99.66(training accuracy), 97.0%(testing accuracy)\n",
    "\n",
    "**Recommendations to improve the employee performance based on insights from analysis**\n",
    "- Creating an environment by giving flexible working hours.\n",
    "- focus on these things in order to boost up performance of employees, as such employees will give excellent performance, more in numbers.\n",
    "- Creating positive envirnoment int he company.\n",
    "- Refreshment area and many more fun activities.\n",
    "- Promote Employees more often in order to make them feel more job oriented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a0265a",
   "metadata": {},
   "source": [
    "# PrettyTable is created to analyse the test and train scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e506a55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+----------+----------+-----------+--------+\n",
      "|            Model(Train)            | f1_score | accuracy | precision | recall |\n",
      "+------------------------------------+----------+----------+-----------+--------+\n",
      "|         Gradient Boosting          |  99.66   |  99.66   |   99.73   | 99.59  |\n",
      "|        Decision Tree(tuned)        |  98.03   |  98.04   |   98.77   | 97.30  |\n",
      "|        Random Forest(tuned)        |  99.46   |  99.46   |   99.32   | 99.59  |\n",
      "| Support Vector Machine(calssifier) |  98.98   |  98.99   |   99.86   | 98.11  |\n",
      "+------------------------------------+----------+----------+-----------+--------+\n",
      "+------------------------------------+----------+----------+-----------+--------+\n",
      "|            Model(Test)             | f1_score | accuracy | precision | recall |\n",
      "+------------------------------------+----------+----------+-----------+--------+\n",
      "|         Gradient Boosting          |  98.27   |   97.0   |   98.84   | 97.71  |\n",
      "|        Decision Tree(tuned)        |  97.88   |  96.33   |   99.21   | 96.57  |\n",
      "|        Random Forest(tuned)        |  97.90   |  96.33   |   98.09   | 97.71  |\n",
      "| Support Vector Machine(calssifier) |  95.81   |   92.6   |   95.81   | 95.81  |\n",
      "+------------------------------------+----------+----------+-----------+--------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "x=PrettyTable()\n",
    "y=PrettyTable()\n",
    "\n",
    "x.field_names = [\"Model(Train)\", \"f1_score\",\"accuracy\",\"precision\",\"recall\"]\n",
    "x.add_row([\"Gradient Boosting\", \"99.66\",'99.66','99.73','99.59'])\n",
    "x.add_row([\"Decision Tree(tuned)\", \"98.03\",'98.04','98.77','97.30'])\n",
    "x.add_row([\"Random Forest(tuned)\", \"99.46\",'99.46','99.32','99.59'])\n",
    "x.add_row([\"Support Vector Machine(calssifier)\", \"98.98\",'98.99','99.86','98.11'])\n",
    "\n",
    "\n",
    "\n",
    "y.field_names = [\"Model(Test)\", \"f1_score\",\"accuracy\",\"precision\",\"recall\"]\n",
    "y.add_row([\"Gradient Boosting\", \"98.27\",'97.0','98.84','97.71'])\n",
    "y.add_row([\"Decision Tree(tuned)\", \"97.88\",'96.33','99.21','96.57'])\n",
    "y.add_row([\"Random Forest(tuned)\", \"97.90\",'96.33','98.09','97.71'])\n",
    "y.add_row([\"Support Vector Machine(calssifier)\", \"95.81\",'92.6','95.81','95.81'])\n",
    "\n",
    "\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e8d2bf",
   "metadata": {},
   "source": [
    "- **Gradient boosting** - 99.66(training accuracy),97.0%(testing accuracy)\n",
    "- **Decision Tree(tuned)** 98.04%(training accuracy),96.33%(testing accuracy)\n",
    "- **Random Forest(tuned)** - 99.46%(training accuracy),96.33%(testing accuracy)\n",
    "- **Support Vector Machine(calssifier)**- 98.99%(training accuracy),92.6%(testing accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d23705c",
   "metadata": {},
   "source": [
    "# Exploratory data analysis\n",
    "\n",
    "# UNIVARIATE ANALYSIS:-\n",
    "- Univariate analysis is a form of analysis that only involves a single variable.It means the analysis of a single variable (or column) in a dataset.\n",
    "- Univariate analysis is the simplest kind of data analysis in the field of statistics.\n",
    "- Univariate analysis explores each variable in a data set, separately. It looks at the range of values, as well as the central tendency of the values. It describes the pattern of response to the variable. It describes each variable on its own.Descriptive statistics describe and summarize data. Univariate descriptive statistics describe individual variables.\n",
    "- For better understanding and visualisation of the data the bivariate and the multivariate analysis is used.\n",
    "\n",
    "###### VISUALIZATION OF CONTINUOUS FEATURES:-\n",
    "\n",
    "**continuous features:**- It takes any measured value within a specific range. Continuous features can be visualized using different plot mentioned below.\n",
    "- Histogram: A histogram is a graph used to show frequency distribution where data are grouped into continuous ranges and each range corresponds to a vertical bar. The horizontal axis represents the number range while the vertical axis represents the amount of data that is present in a range.\n",
    "\n",
    "###### VISUALIZATION OF DISCRETE AND CATEGORICAL FEATURES:-\n",
    "\n",
    "**Discrete and Categorical:**- Discrete features takes specific countable values. Categorical data is a type of data that is used to group information with similar characteristics.\n",
    "-Discrete features can be visualized using different plots mentioned below.\n",
    "- Countplot: A Countplot is used to represent the counts of observations in each categorical variables using bars.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a527d0b3",
   "metadata": {},
   "source": [
    "# BIAVARIATE ANALYSIS\n",
    "\n",
    "- Bivariate analysis is one of the simplest forms of quantitative (statistical) analysis. It involves the analysis of two variables (often denoted as X, Y), for the purpose of determining the empirical relationship between them.\n",
    "- In order words, it is meant to determine any concurrent relationship between different variables and finally to extract relevant relationships for better understanding of the data\n",
    "\n",
    "### BARPLOT\n",
    "- A barplot (or barchart) is one of the most common types of graphic. It shows the relationship between a numeric and a categoric variable. Each entity of the categoric variable is represented as a bar. The size of the bar represents its numeric value.\n",
    "\n",
    "### Lineplot\n",
    "- A line plot is a type of plot in Seaborn that shows the relationship between two continuous variables by connecting the data points with a straight line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d136e32a",
   "metadata": {},
   "source": [
    "# MULTIVARIANT ANALYSIS:-\n",
    "\n",
    "- Multiple regression is the most commonly utilized multivariate technique. It examines the relationship between a single metric dependent variable and two or more metric independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40946b3d",
   "metadata": {},
   "source": [
    "- In this project, a detailed exploratory data analysis was done on the data.Exploratory data analysis was done through various charts, plots, graphs to find out the relationship between the numerical-categorical features and also numerical-numerical features.\n",
    "- Also, EDA was done on both Continous and Numerical features.\n",
    "- To find out the distribution of the features the distplot was used, it is important is check the distribution of the data for outlier handling and also for imputing the missing values.\n",
    "- This particular dataset doesn't have any missing values in it nor it has any duplicate records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b9e46d",
   "metadata": {},
   "source": [
    "# SUMMARY OF EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdd9128",
   "metadata": {},
   "source": [
    "- The male and female employees work life balance are almost same for both the gender.\n",
    "- When the employees have received YearsSinceLastPromotion more than 2.0, the employees are not leaving the company.\n",
    "- when the employees have received YearsSinceLastPromotion less than 2.0, the employees are leaving the company.\n",
    "- Data science employees has the lowest experience years in current role.\n",
    "- The employees job role Manager has the highest experience years in current role followed by Research Director.\n",
    "- Technical Architect has the lowest experience years in current role.\n",
    "- The Human Resources has the highest Employee job involvement.\n",
    "- Technical degree and other has the lowest Employee job involvement.\n",
    "- The employees working in the Human resources educational background has worked in more than 3 companies.\n",
    "- The male employees are more frequent to leave the job.\n",
    "- The EmpLastSalaryHikePercent between 22 and 24 has the highest YearsSinceLastPromotion when the performance rating is 4\n",
    "- The EmpLastSalaryHikePercent between 22 and 24 has the highest YearsSinceLastPromotion when the performance rating is 3\n",
    "- The EmpLastSalaryHikePercent between 22 and 24 has the highest YearsSinceLastPromotion when the performance rating is 2\n",
    "- The maximum YearsSinceLastPromotion is between 0 to 6 for all the performance rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74202a4f",
   "metadata": {},
   "source": [
    "# STATISTICAL ANALYSIS OF THE DATA\n",
    "\n",
    "**Basic checks-**\n",
    "- Various basic checks such as checking the shape and size of the data,checking the missing values, checking the duplicate records was done successfully.\n",
    "- It was found that there were no missing values, no duplicate records and also no constant values in the features.\n",
    "\n",
    "**Distribution of continuous features.**\n",
    "- Distribution can be divided into normal distribution and skewed distribution.\n",
    "- The age feature was considered as Normally distributed feature.\n",
    "- The features DistanceFromHome,EmpLastSalaryHikePercent,TotalWorkExperienceInYears,ExperienceYearsAtThisCompany,ExperienceYearsInCurrentRole, YearsSinceLastPromotion,YearsWithCurrManager are skewed distribution i.e Right skewed also known as Positive skewed distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c63d79c",
   "metadata": {},
   "source": [
    "**DEPARTMENT WISE PERFORMANCE RATING**\n",
    "\n",
    "- Barplot,violinplot are used to bring out neccessary insights from the particular features.\n",
    "\n",
    "- **OBSERVATION-**\n",
    "\n",
    "- EmpDepartment Development department shows High performance rating as shown in the above graphs\n",
    "\n",
    "- Sales: The Performace rating level 3 is maximum in the sales department. The male employees performance rating is higher than the female employees.The employees not leaving the company is higher.\n",
    "\n",
    "- Human Resources: The Performace rating level 3 is maximum in the Human resource department.The female employee rating is higher than the male employees. The employees not leaving the company is higher.\n",
    "\n",
    "- Development: The performance rating 3 has the maximum counts.The gender-based performance is nearly same for both.\n",
    "The employee not leaving the company is higher.\n",
    "\n",
    "- Data Science: The performance rating 3 has the maximum counts in data science department. Data science is the only department where less number of level 2 performers and level 1 performers are present.Male employees are performing well. The employees not leaving the company is higher and the data science is the department which has a overall performance better than the other cdepartments.\n",
    "\n",
    "- Research & Development: The performance rating 3 has the maximum counts. The female employees has higher performance rating than the males. The employees not leaving the company is higher\n",
    "\n",
    "- Finance: The performance rating 3 has the maximum counts. The male employees has higher performance rating than the males. The employees not leaving the company is higher.\n",
    "\n",
    "\n",
    "- In all the departments the age of the employees doesn't exceed 40 years.\n",
    "- The department which has the youngest employees is the Development department."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69f203d",
   "metadata": {},
   "source": [
    "In the visualization notebook, it was visualized that these three features plays an important role in determining the performance rating of the employees.\n",
    "- EmpLastSalaryHikePercent\n",
    "- EmpEnvironmentSatisfaction\n",
    "- YearsSinceLastPromotion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f8b830",
   "metadata": {},
   "source": [
    "**Mean distribution of the entire data**\n",
    "- The entire data as a whole is normally distributed.\n",
    "- The mean value is nearly 9 to 9.5\n",
    "- From the graph it can be concluded that most of the data lies between 8 to 12 and the range is 4 to 20."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81faf34",
   "metadata": {},
   "source": [
    "**Median distribution of the entire data**\n",
    "- The entire data as a whole is normally distributed.\n",
    "- the range is from 0 to 8\n",
    "- Maximum of the data lies between 2 to 4 which is considered as the median or the middle value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff42e7ea",
   "metadata": {},
   "source": [
    "\n",
    "**Standard Deviation distribution of entire data**\n",
    "- Distribution of standard deviation of data also look like guassian distribution around 30% of feature standard deviation around the range of 3 3 to 20 and remaining 70% feature standard deviation in between 0 to 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d8482f",
   "metadata": {},
   "source": [
    "**Skewness and kurtosis of the data**\n",
    "\n",
    "- Skewness is a measurement of the distortion of symmetrical distribution or asymmetry in a data set. Skewness is demonstrated on a bell curve when data points are not distributed symmetrically to the left and right sides of the median on a bell curve. If the bell curve is shifted to the left or the right, it is said to be skewed.\n",
    "- Kurtosis is a measure of the tailedness of a distribution. Tailedness is how often outliers occur.\n",
    "- There are different types of kurtosis- \n",
    "- A mesokurtic distribution is medium-tailed, so outliers are neither highly frequent, nor highly infrequent.\n",
    "\n",
    "- Feature skewness was checked using statistical method and it was found that the feature **Year Since Last Promotion Feature**, **Total Work Experiance In Year Feature** and **Experiance Year At This Company Feature** have skewed data as the value among the other features is higher so we need to do feature transformation in data preprocessing.\n",
    "- Feature transformation is done in features which has skewness of more than 1.\n",
    "- The Skewness of Year Since Last Promotion Feature : 1.9749315589155791\n",
    "- The kurtosis of Year Since Last Promotion Feature : 3.5390800793468817\n",
    "\n",
    "- The Skewness of Total Work Experiance In Year Feature : 1.0868618597364565\n",
    "- The kurtosis of Total Work Experiance In Year Feature : 0.8056333333819827\n",
    "\n",
    "- The Skewness of Experiance Year At This Company Feature : 1.789054979919473\n",
    "- The kurtosis of Experiance Year At This Company Feature : 4.057959404441291\n",
    "\n",
    "- Since these features has skewness more than 1 so square root transformation was used for better performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7127acaf",
   "metadata": {},
   "source": [
    "# DATA PRE-PROCESSING\n",
    "\n",
    "- The data pre-processing was done by handling the outliers,Categorical encoding,Feature Transformation,Feature scaling using MinMaxScaler,Checking for feature correlation,Feature Importance.\n",
    "\n",
    "**Handling outliers-**\n",
    "- The plot i.e Boxplot was used to detect the outliers.The features TotalWorkExperienceInYears,ExperienceYearsAtThisCompany and YearsSinceLastPromotion was selected for the outlier handling because the rest of the features are discrete features.\n",
    "- Since, the above mentioned features are skewed distribution so median is used for the outlier handling and the method used is IQR.\n",
    "\n",
    "**Categorical encoding**\n",
    "- Encoding categorical data is a process of converting categorical data into integer format so that the data with converted categorical values can be provided to the models to give and improve the predictions.\n",
    "- A structured data contains multiple columns with both numerical and categorical features.It is important to convert the categorical features into numerical features because the machine are incapable of understanding text.Instead they can only understand numbers.\n",
    "- **One hot encoding** - One-hot encoding in machine learning is the conversion of categorical information into a format that may be fed into machine learning algorithms to improve prediction accuracy.\n",
    "- **Label Encoding** - Label Encoding refers to converting the labels into a numeric form so as to convert them into the machine-readable form. Machine learning algorithms can then decide in a better way how those labels must be operated. It is an important pre-processing step for the structured dataset in supervised learning.Each label is assigned a unique integer based on alphabetical ordering.\n",
    "\n",
    "- **CONVERTING THE MULTICLASS CLASSIFICATION TASK INTO BINARY CLASSIFICATION TASK**\n",
    "\n",
    "**Feature Transformation**\n",
    "- Function transformers are the type of feature transformation technique that uses a particular function to transform the data to the normal distribution\n",
    "- In this project square root transformation technique was used for better performance.\n",
    "\n",
    "\n",
    "The feature **Year Since Last Promotion Feature**, **Total Work Experiance In Year Feature** and **Experiance Year At This Company Feature** have skewed data so feature transformation was done.\n",
    "\n",
    "**Dropping the features**\n",
    "\n",
    "**ExperienceYearsAtThisCompany,YearsSinceLastPromotion,TotalWorkExperienceInYears,EmpNumber was dropped because new column i.e squ_YearsSinceLastPromotion, squ_TotalWorkExperienceInYears,squ_ExperienceYearsAtThisCompany was created***\n",
    "\n",
    "**Feature scaling by StandardScaler**\n",
    "- In Machine Learning, StandardScaler is used to resize the distribution of values so that the mean of the observed values is 0 and the standard deviation is 1.\n",
    "- All the features except the target feature is not scaled.\n",
    "\n",
    "**checking for correlation-**\n",
    "- In this data no correlation was found between the data.\n",
    "- PCA technique was not used as the performance of the model was low because PCA is performed when the features are highly correlated to each other, but as per the data it doesn't have nay correlation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e354f6b",
   "metadata": {},
   "source": [
    "# Model Creation and Evaluation of Testing data and training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbf076f",
   "metadata": {},
   "source": [
    "**AIM OF MODEL CREATION AND EVALUATION**\n",
    "To create a generalised model having low bias and low variance\n",
    "\n",
    "**low bias means low training error**\n",
    "\n",
    "**low variance means low testing error**\n",
    "\n",
    "- The pre-processed data was loaded and read.\n",
    "- Defining the independent features and the dependent feature.\n",
    "- Spliting the dataset into training and testing data.\n",
    "- here 75% of the data is used for training and 25% of the data is used for testing.\n",
    "- Balancing the data using SMOTE.\n",
    "\n",
    "**SMOTE**\n",
    "\n",
    "- SMOTE stands for Synthetic Minority Oversampling Technique.\n",
    "- It is a statistical technique for increasing the number of cases in the dataset in a balanced way. The component works by generating new instances from existing minority cases that you supply as input.\n",
    "- SMOTE works by utilizing a k-nearest neighbour algorithm to create synthetic data.\n",
    "- SMOTE first starts by choosing random data from the minority class, then k-nearest neighbors from the data are set.\n",
    "- It is done when the dataset is imbalance in case of Classification task.\n",
    "\n",
    "**ALGORITHMS**\n",
    "- The word Algorithm means ” A set of finite rules or instructions to be followed in calculations or other problem-solving operations.\n",
    "\n",
    "**ALGORITHMS USED**\n",
    "- Logistic Regression\n",
    "- Support Vector Machine(Classifier)\n",
    "- Support Vector Machine(Classifier)-Hyperparameter tuning.\n",
    "- K-Nearest Neighbour(Classifier)\n",
    "- K-Nearest Neighbour(Bagging)-Ensemble technique.\n",
    "- Decision Tree(Classifier)\n",
    "- Decision Tree(Classifier)-Hyperparameter tuning.\n",
    "- Random Forest.\n",
    "- Random Forest-Hyperparameter tuning\n",
    "- Gradient Bossting- Boosting Technique.\n",
    "- Artificial Neural Network.\n",
    "\n",
    "**Best Algorithms for the given task**\n",
    "\n",
    "**Support Vector Machine(calssifier)**\n",
    "- Support Vector Machine or SVM is one of the most popular Supervised Learning algorithms, which is used for Classification as well as Regression problems. However, primarily, it is used for Classification problems in Machine Learning.\n",
    "- The goal of the SVM algorithm is to create the best line or decision boundary that can segregate n-dimensional space into classes so that we can easily put the new data point in the correct category in the future. This best decision boundary is called a hyperplane.\n",
    "- It works best on smaller datasets.\n",
    "\n",
    "**Decision tree(Classifier)[TUNED]**\n",
    "- A decision tree is a non-parametric supervised learning algorithm, which is utilized for both classification and regression tasks. It has a hierarchical, tree structure, which consists of a root node, branches, internal nodes and leaf nodes.\n",
    "- Practically decision tree with smaller dataset overfits so decision tree tuned worked well in this dataset.\n",
    "\n",
    "**Random Forest(Classifier)[TUNED]**\n",
    "- It is an Ensembled technique\n",
    "- Random forest is a commonly uses machine learning algorithm which combines the output of multiple decision trees to reach a single result.\n",
    "\n",
    "**Gradient boosting**\n",
    "- Gradient boosting is one of the variants of ensemble methods where you create multiple weak models and combine them to get better performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1aa6be",
   "metadata": {},
   "source": [
    "# Challenges Faced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3375a6",
   "metadata": {},
   "source": [
    "- Smaller dataset but complex dataset.\n",
    "- Conversion of multi-class classification task to binary classification for easy model evaluation.\n",
    "- Various trial and error was done with the dataset by using PCA techniques and also by outlier handling of all the features.But the scores were not up to the mark so PCA was not included so only selected features were selected based on the feature importance for handling outliers thus resulting in good performance of the model i.e generalised model.\n",
    "- Initially no transformation was done and checked the performance score of the model which resulted in a worst performance so in order to improve the model's overall score square root transformation was used.\n",
    "- Data preprocessing and data exploration.\n",
    "- To select a best model was also a challege."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb316477",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328bf608",
   "metadata": {},
   "source": [
    "The References used for completing this project are-\n",
    "- **AnalyticsVidya.com**\n",
    "- **https://www.enjoyalgorithms.com/blog/univariate-bivariate-multivariate-analysis**\n",
    "- **Coursera.com****\n",
    "- **jstor.com****\n",
    "- **performyard.com**\n",
    "\n",
    "All of the above mentioned sites helped me in understanding the concepts and also helped me in successfully completing the project on time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4a0a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
